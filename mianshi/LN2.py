import tensorflow as tf

gpus = tf.config.experimental.list_physical_devices(device_type='GPU')
for gpu in gpus:
    tf.config.experimental.set_memory_growth(gpu, True)

tf.random.set_seed(1234)

x1 = tf.random.normal((4, 2, 2, 3), mean=10, stddev=10.0)

x2 = tf.keras.layers.LayerNormalization(axis=(1, 2))(x1)
# tensorflow实现
tf.print(x2)
'''
[[[[1.13592184 -1.01682484 1.41455]
   [0.0445363373 -0.999791801 1.46824622]]
  [[1.22681248 -1.01918077 -0.505445421]
   [-0.84361434 0.0935621038 -0.998772383]]]
 [[[0.241638556 1.41170228 -0.189664766]
   [1.75422382 0.253618807 0.203838587]]
  [[-0.0914538875 0.0727662146 0.206310436]
   [-2.27698731 -0.453317314 -1.13267565]]]
 [[[0.660608232 -1.50688756 -1.25433147]
   [-0.108726673 0.251018792 1.11019969]]
  [[1.55131137 -0.91692245 1.37210977]
   [0.350336075 -0.651512 -0.857205331]]]
 [[[-1.13443768 0.891957879 -1.49989474]
   [0.853844702 2.05934501 -0.13168712]]
  [[-0.669010222 -1.08240855 0.9768731]
   [-0.31119889 -0.043616 0.0902313]]]]
'''

x_mean = tf.reduce_mean(x1, axis=(1, 2))
print(x_mean)  # (10,)

x_mean = tf.reshape(x_mean, (-1, 1, 1, 3))
# print(x_mean.shape)  # (10, 1, 1, 1)


x_std = tf.math.reduce_std(x1, axis=(1, 2))
print(x_std)
x_std = tf.reshape(x_std, (-1, 1, 1, 3))

x3 = (x1 - x_mean) / x_std
# 手动实现
tf.print(x3)  # 可以发现两种方式差不多
'''
[[[[1.13593256 -1.01683426 1.4145633]
   [0.0445368551 -0.99980104 1.46826017]]
  [[1.22682405 -1.01919019 -0.50545007]
   [-0.843622148 0.0935630798 -0.998781621]]]
 [[[0.241640702 1.41171491 -0.18966648]
   [1.75423956 0.253621072 0.203840405]]
  [[-0.091454722 0.0727668479 0.206312269]
   [-2.27700782 -0.453321397 -1.1326859]]]
 [[[0.660612881 -1.50689745 -1.25433969]
   [-0.108727202 0.25102067 1.11020732]]
  [[1.55132198 -0.916928411 1.37211931]
   [0.350338638 -0.651516199 -0.857210875]]]
 [[[-1.13444376 0.891962826 -1.49990284]
   [0.853849471 2.05935621 -0.131687731]]
  [[-0.669013798 -1.08241439 0.976878583]
   [-0.31120047 -0.0436161309 0.0902319]]]]
'''